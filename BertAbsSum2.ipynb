{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "BertAbsSum2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brs1977/BERT-Transformer-for-Summarization/blob/master/BertAbsSum2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaZKzBPJtms6",
        "colab_type": "text"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dbzj0kSta8L",
        "colab_type": "text"
      },
      "source": [
        "##Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DKufDQceuaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7h5IEsJfJs7",
        "colab_type": "text"
      },
      "source": [
        "##Get Kaggle data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ7V-uhSfIYk",
        "colab_type": "code",
        "outputId": "b688fdc3-7266-4a0c-eb3d-df1401d0cc11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#!pip install -q kaggle\n",
        "\n",
        "#kaggle key\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/drive/My\\ Drive/kaggle.json ~/.kaggle\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h32t1QHfQk8",
        "colab_type": "code",
        "outputId": "d1cedf98-5087-4b2a-8290-938519ac27cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "!kaggle competitions download -c title-generation"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content\n",
            " 94% 41.0M/43.7M [00:00<00:00, 51.5MB/s]\n",
            "100% 43.7M/43.7M [00:00<00:00, 111MB/s] \n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/778k [00:00<?, ?B/s]\n",
            "100% 778k/778k [00:00<00:00, 108MB/s]\n",
            "Downloading test.csv to /content\n",
            "  0% 0.00/905k [00:00<?, ?B/s]\n",
            "100% 905k/905k [00:00<00:00, 128MB/s]\n",
            "Downloading vocs.pkl.zip to /content\n",
            "  0% 0.00/6.39M [00:00<?, ?B/s]\n",
            "100% 6.39M/6.39M [00:00<00:00, 58.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpltIhc-fVqS",
        "colab_type": "code",
        "outputId": "a46b7319-b45a-47f9-9e27-8e2a46be69b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "!mkdir data\n",
        "!unzip sample_submission.csv.zip -d data\n",
        "!unzip vocs.pkl.zip -d data\n",
        "!unzip train.csv.zip -d data\n",
        "!mv test.csv data\n",
        "\n",
        "!ls data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: data/sample_submission.csv  \n",
            "Archive:  vocs.pkl.zip\n",
            "  inflating: data/vocs.pkl           \n",
            "Archive:  train.csv.zip\n",
            "  inflating: data/train.csv          \n",
            "sample_submission.csv  test.csv  train.csv  vocs.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiawlFnGfbV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('/content/data/train.csv', encoding='utf8')\n",
        "test = pd.read_csv('/content/data/test.csv', encoding='utf8')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0288Y3gPfc8a",
        "colab_type": "code",
        "outputId": "e0b8b8a7-b169-4d48-e77d-45b6051d3eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we consider the problem of utility maximizatio...</td>\n",
              "      <td>on optimal investment with processes of long o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>in this paper we provide an explicit formula f...</td>\n",
              "      <td>boolean complexes for ferrers graphs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>kinesin-5, also known as eg5 in vertebrates is...</td>\n",
              "      <td>relative velocity of sliding of microtubules b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>we discuss the transition paths in a coupled b...</td>\n",
              "      <td>bifurcation of transition paths induced by cou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>two types of room temperature detectors of ter...</td>\n",
              "      <td>all-electric detectors of the polarization sta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            abstract                                              title\n",
              "0  we consider the problem of utility maximizatio...  on optimal investment with processes of long o...\n",
              "1  in this paper we provide an explicit formula f...               boolean complexes for ferrers graphs\n",
              "2  kinesin-5, also known as eg5 in vertebrates is...  relative velocity of sliding of microtubules b...\n",
              "3  we discuss the transition paths in a coupled b...  bifurcation of transition paths induced by cou...\n",
              "4  two types of room temperature detectors of ter...  all-electric detectors of the polarization sta..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CjNvi4nfhFc",
        "colab_type": "text"
      },
      "source": [
        "##Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWO9FdL0fB5v",
        "colab_type": "code",
        "outputId": "837edef3-d4f5-404c-9814-408a15689ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "%cd /content\n",
        "!rm bertsum -r\n",
        "!git clone https://github.com/brs1977/BERT-Transformer-for-Summarization bertsum\n",
        "\n",
        "# !git pull origin master"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "rm: cannot remove 'bertsum': No such file or directory\n",
            "Cloning into 'bertsum'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 122 (delta 55), reused 80 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (122/122), 135.88 KiB | 3.77 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvZ-_YvEeQLk",
        "colab_type": "code",
        "outputId": "01fce2dc-8065-4c03-af88-d6350076c1cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/bertsum\n",
        "\n",
        "import random\n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "from preprocess import CSVProcessor, create_dataset\n",
        "from model import BertAbsSum\n",
        "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "from pytorch_pretrained_bert.modeling import BertModel\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "from preprocess import convert_examples_to_features\n",
        "from tqdm import tqdm, trange\n",
        "from transformer import Constants"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/bertsum\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBJiX709huHD",
        "colab_type": "text"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuFtKU0eiDwi",
        "colab_type": "text"
      },
      "source": [
        "###Bert config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH4VXzObeQLx",
        "colab_type": "code",
        "outputId": "1fdb4047-235b-4ef6-e5ad-e554f27546c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
        "                    level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class ARGS(object):\n",
        "    data_dir = 'data/processed_data'\n",
        "    bert_model = 'bert-base-uncased'\n",
        "    #output_dir = 'output'\n",
        "    output_dir = '/content/drive/My Drive/nlp'\n",
        "    config_path = 'config.json'\n",
        "    model_path =  '/content/drive/My Drive/nlp/model_01-31-15:26:20/BertAbsSum_2.bin' #Rouge-1: 0.7403979126348502 Rouge-2: 0.593938859194881\n",
        "    learning_rate = 2e-5\n",
        "    change_lr = True\n",
        "    load_prepared_data = True\n",
        "    num_train_epochs = 5\n",
        "    warmup_proportion = 0.1\n",
        "    max_src_len = 130\n",
        "    max_tgt_len = 30\n",
        "    train_batch_size = 48\n",
        "    valid_batch_size = 48\n",
        "    decoder_config = None\n",
        "    print_every = 100\n",
        "    gradient_accumulation_steps = 8\n",
        "\n",
        "\n",
        "args = ARGS()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "logger.info(f'Using device:{device}')\n",
        "\n",
        "if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)\n",
        "model_path = os.path.join(args.output_dir, time.strftime('model_%m-%d-%H:%M:%S', time.localtime()))\n",
        "os.mkdir(model_path)\n",
        "logger.info(f'Saving model to {model_path}.')\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/01/2020 08:28:05 - INFO - __main__ -   Using device:cuda\n",
            "02/01/2020 08:28:05 - INFO - __main__ -   Saving model to /content/drive/My Drive/nlp/model_02-01-08:28:05.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE6VE9npiQ6t",
        "colab_type": "text"
      },
      "source": [
        "###Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGqDLLzJO1hq",
        "colab_type": "code",
        "outputId": "eada6e43-b1a3-4a61-ebde-955d20ae8f0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "if args.load_prepared_data:\n",
        "  #prepared data\n",
        "  train_data  = torch.load('/content/drive/My Drive/nlp/nlp_model/abs_bert/data130X30/train.pt')\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size, drop_last=True)\n",
        "\n",
        "  valid_data = torch.load('/content/drive/My Drive/nlp/nlp_model/abs_bert/data130X30/valid.pt')\n",
        "  valid_sampler = RandomSampler(valid_data)\n",
        "  valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=args.valid_batch_size, drop_last=True)\n",
        "\n",
        "  tokenizer = BertTokenizer.from_pretrained(args.bert_model)\n",
        "else:\n",
        "  is_test = False\n",
        "  nrows = None if not is_test else 500\n",
        "\n",
        "  # data preprocess\n",
        "  processor = CSVProcessor()\n",
        "  tokenizer = BertTokenizer.from_pretrained(args.bert_model)\n",
        "  # tokenizer = BertTokenizer.from_pretrained(os.path.join(args.bert_model, 'vocab.txt'))\n",
        "  logger.info('Loading train examples...')\n",
        "  train_examples = processor.get_train_examples('../data/train.csv', nrows = nrows)\n",
        "  num_train_optimization_steps = int(len(train_examples) / args.train_batch_size / args.gradient_accumulation_steps) * args.num_train_epochs\n",
        "  logger.info('Converting train examples to features...')\n",
        "  train_features = convert_examples_to_features(train_examples, args.max_src_len, args.max_tgt_len, tokenizer)\n",
        "  example = train_examples[0]\n",
        "  example_feature = train_features[0]\n",
        "  logger.info(\"*** Example ***\")\n",
        "  logger.info(\"guid: %s\" % (example.guid))\n",
        "  logger.info(\"src text: %s\" % example.src)\n",
        "  logger.info(\"src_ids: %s\" % \" \".join([str(x) for x in example_feature.src_ids]))\n",
        "  logger.info(\"src_mask: %s\" % \" \".join([str(x) for x in example_feature.src_mask]))\n",
        "  logger.info(\"tgt text: %s\" % example.tgt)\n",
        "  logger.info(\"tgt_ids: %s\" % \" \".join([str(x) for x in example_feature.tgt_ids]))\n",
        "  logger.info(\"tgt_mask: %s\" % \" \".join([str(x) for x in example_feature.tgt_mask]))\n",
        "  logger.info('Building dataloader...')\n",
        "  train_data = create_dataset(train_features)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=args.train_batch_size, drop_last=True)\n",
        "\n",
        "  valid_examples = processor.get_valid_examples('../data/train.csv')\n",
        "  logger.info('Converting valid examples to features...')\n",
        "  valid_features = convert_examples_to_features(valid_examples, args.max_src_len, args.max_tgt_len, tokenizer)\n",
        "  valid_data = create_dataset(valid_features)\n",
        "  valid_sampler = RandomSampler(valid_data)\n",
        "  valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=args.train_batch_size, drop_last=True)  \n",
        "\n",
        "# save prepared data\n",
        "# torch.save(train_data,'train.pt')\n",
        "# torch.save(valid_data,'valid.pt')\n",
        "# !cp *.pt /content/drive/My\\ Drive/nlp/nlp_model/abs_bert/data130X30\n",
        "# !ls /content/drive/My\\ Drive/nlp/nlp_model/abs_bert/data130X30 -la\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/01/2020 08:23:27 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmptqugw4wn\n",
            "100%|██████████| 231508/231508 [00:00<00:00, 2635955.76B/s]\n",
            "02/01/2020 08:23:27 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmptqugw4wn to cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "02/01/2020 08:23:27 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "02/01/2020 08:23:27 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmptqugw4wn\n",
            "02/01/2020 08:23:27 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uok4w6IzVo7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNny66w7ioT7",
        "colab_type": "text"
      },
      "source": [
        "###Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx8bd6jR3C_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_performance(logits, ground, smoothing=True):\n",
        "    ground = ground[:, 1:]\n",
        "    logits = logits.view(-1, logits.size(-1))\n",
        "    ground = ground.contiguous().view(-1)\n",
        "\n",
        "    loss = cal_loss(logits, ground, smoothing=smoothing)\n",
        "\n",
        "    pad_mask = ground.ne(Constants.PAD)\n",
        "    pred = logits.max(-1)[1]\n",
        "    correct = pred.eq(ground)\n",
        "    correct = correct.masked_select(pad_mask).sum().item()\n",
        "    return loss, correct\n",
        "\n",
        "def cal_loss(logits, ground, smoothing=True):\n",
        "    def label_smoothing(logits, labels):\n",
        "        eps = 0.1\n",
        "        num_classes = logits.size(-1)\n",
        "\n",
        "        # >>> z = torch.zeros(2, 4).scatter_(1, torch.tensor([[2], [3]]), 1.23)\n",
        "        # >>> z\n",
        "        # tensor([[ 0.0000,  0.0000,  1.2300,  0.0000],\n",
        "        #        [ 0.0000,  0.0000,  0.0000,  1.2300]])\n",
        "        one_hot = torch.zeros_like(logits).scatter(1, labels.view(-1, 1), 1)\n",
        "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (num_classes - 1)\n",
        "        log_prb = F.log_softmax(logits, dim=1)\n",
        "        non_pad_mask = ground.ne(Constants.PAD)\n",
        "        loss = -(one_hot * log_prb).sum(dim=1)\n",
        "        loss = loss.masked_select(non_pad_mask).mean()\n",
        "        return loss\n",
        "    if smoothing:\n",
        "        loss = label_smoothing(logits, ground)\n",
        "    else:\n",
        "        loss = F.cross_entropy(logits, ground, ignore_index=Constants.PAD)\n",
        "    \n",
        "    return loss    \n",
        "\n",
        "def rouge(hyp, ref, n):\n",
        "    scores = []\n",
        "    for h, r in zip(hyp, ref):\n",
        "        r = re.sub(r'[UNK]', '', r)\n",
        "        r = re.sub(r'[’!\"#$%&\\'()*+,-./:：？！《》;<=>?@[\\\\]^_`{|}~]+', '', r)\n",
        "        r = re.sub(r'\\d', '', r)\n",
        "        r = re.sub(r'[a-zA-Z]', '', r)\n",
        "        count = 0\n",
        "        match = 0\n",
        "        for i in range(len(r) - n):\n",
        "            gram = r[i:i + n]\n",
        "            if gram in h:\n",
        "                match += 1\n",
        "            count += 1\n",
        "        scores.append(0 if count==0 else match / count)\n",
        "    return np.average(scores)\n",
        "\n",
        "def convert_one_example(text, src_max_seq_length, tokenizer):\n",
        "    src_tokens = tokenizer.tokenize(text)\n",
        "    if len(src_tokens) > src_max_seq_length - 2:\n",
        "        src_tokens = src_tokens[:(src_max_seq_length - 2)]\n",
        "    src_tokens = [\"[CLS]\"] + src_tokens + [\"[SEP]\"]\n",
        "\n",
        "    src_ids = tokenizer.convert_tokens_to_ids(src_tokens)\n",
        "\n",
        "    src_mask = [1] * len(src_ids)\n",
        "    src_padding = [0] * (src_max_seq_length - len(src_ids))\n",
        "    src_ids += src_padding\n",
        "    src_mask += src_padding\n",
        "\n",
        "    return torch.tensor([src_ids]), torch.tensor([src_mask])   \n",
        "\n",
        "def compute_lr(initAlpha,epoch,power=1,maxEpochs=5):\n",
        "    # maxEpochs  : общее количество эпох, для которых мы будем тренироваться.\n",
        "    # initAlpha  : начальная скорость обучения.\n",
        "    # power: степень / показатель многочлена.\n",
        "    # power = 1,0, линейный спад скорости обучения.\n",
        "\t\t# compute the new learning rate based on polynomial decay\n",
        "\t\tdecay = (1 - (epoch / float(maxEpochs))) ** power\n",
        "\t\talpha = initAlpha * decay\n",
        " \n",
        "\t\t# return the new learning rate\n",
        "\t\treturn float(alpha)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1dhUYPgjhW3",
        "colab_type": "text"
      },
      "source": [
        "###Validation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSNeu5s1jlGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "def do_validate(beam_size=3, n_best=3, seed=666):\n",
        "  logger.info(\"***** Running validation *****\")\n",
        "  set_seed(seed)\n",
        "  model.eval()\n",
        "  hyp_list = []\n",
        "  ref_list = []\n",
        "  i = 0\n",
        "  for batch in tqdm(valid_dataloader, desc=\"Val iter\", position=0):\n",
        "      i += 1\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      pred, _ = model.beam_decode(batch[0], batch[1], beam_size=beam_size, n_best=n_best)\n",
        "      src, tgt = batch[0], batch[2]\n",
        "      for i in range(args.train_batch_size):\n",
        "          sample_src = \"\".join(tokenizer.convert_ids_to_tokens(src[i].cpu().numpy())).split('[CLS]')[1].split('[SEP]')[0] + '\\n'\n",
        "          sample_tgt = \"\".join(tokenizer.convert_ids_to_tokens(tgt[i].cpu().numpy())).split('[CLS]')[1].split('[SEP]')[0] + '\\n'\n",
        "          sample_pred = \"\".join(tokenizer.convert_ids_to_tokens(pred[i][0])).split('[SEP]')[0] + '\\n'\n",
        "\n",
        "          hyp_list.append(sample_pred)\n",
        "          ref_list.append(sample_tgt)\n",
        "  rouge_1 = rouge(hyp_list, ref_list, 1)\n",
        "  rouge_2 = rouge(hyp_list, ref_list, 2)\n",
        "  logger.info('******Validation results******')\n",
        "  logger.info(f'beam_size: {beam_size} n_best: {n_best} Rouge-1: {rouge_1} Rouge-2: {rouge_2}')\n",
        "  logger.info('Validation finished.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtGK6INWjlKP",
        "colab_type": "code",
        "outputId": "b4c186c4-37a5-417e-aaf5-b5263b10143d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# do_validate()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01/28/2020 05:03:31 - INFO - __main__ -   ***** Running validation *****\n",
            "Val iter: 100%|██████████| 422/422 [27:13<00:00,  3.73s/it]\n",
            "01/28/2020 05:30:46 - INFO - __main__ -   ******Validation results******\n",
            "01/28/2020 05:30:46 - INFO - __main__ -   Rouge-1: 0.7187769614570536\n",
            "01/28/2020 05:30:46 - INFO - __main__ -   Rouge-2: 0.5851275569921026\n",
            "01/28/2020 05:30:46 - INFO - __main__ -   Validation finished.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLh3CyBgiZKB",
        "colab_type": "text"
      },
      "source": [
        "###Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Q9fMBjsBHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "8ab08cb3-e7a2-45d5-99c6-1146e1d47d4a"
      },
      "source": [
        "num_train_optimization_steps = int(len(train_data) / args.train_batch_size / args.gradient_accumulation_steps) * args.num_train_epochs\n",
        "\n",
        "if args.model_path is None:\n",
        "  model = BertAbsSum(args.bert_model, decoder_config, device=device )\n",
        "  model.to(device)\n",
        "else: #load checkpoint\n",
        "  # args.config_path = '/content/drive/My Drive/nlp/config.json'\n",
        "  with open(args.config_path, 'r') as f:\n",
        "      config = json.load(f)\n",
        "  logger.info(f'******Loading state model {args.model_path}******')\n",
        "  model = BertAbsSum(args.bert_model, config['decoder_config'], device)\n",
        "  model.load_state_dict(torch.load(args.model_path))\n",
        "  model.to(device)\n",
        "\n",
        "\n",
        "# optimizer\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                    lr=args.learning_rate,\n",
        "                    warmup=0.1,\n",
        "                    t_total=num_train_optimization_steps)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/01/2020 08:28:14 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "02/01/2020 08:28:14 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpbq6jj182\n",
            "02/01/2020 08:28:18 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPYc6qiFit8b",
        "colab_type": "text"
      },
      "source": [
        "###Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QD9HwPe3DDv",
        "colab_type": "code",
        "outputId": "76f39a47-714c-4e9e-fd1c-a227c1399e1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "seed = 666\n",
        "# training\n",
        "logger.info(\"***** Running training *****\")\n",
        "logger.info(\"  Num examples = %d\", len(train_data))\n",
        "logger.info(\"  Batch size = %d\", args.train_batch_size)\n",
        "logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
        "model.train()\n",
        "global_step = 0\n",
        "for i in range(int(args.num_train_epochs)):\n",
        "    set_seed(seed)\n",
        "    # do training\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Train iter\", position=0)):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        logits = model(*batch)\n",
        "        loss, _ = cal_performance(logits, batch[2])\n",
        "\n",
        "        if args.gradient_accumulation_steps > 1:\n",
        "            loss = loss / args.gradient_accumulation_steps\n",
        "        loss.backward()\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += batch[0].size(0)\n",
        "        nb_tr_steps += 1\n",
        "        if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1\n",
        "        if (step + 1) % args.print_every == 0:\n",
        "            logger.info(f'Epoch {i}, step {step}, loss {loss.item()}. lr {optimizer.param_groups[0][\"lr\"]}.')\n",
        "            logger.info(f'Ground: {\"\".join(tokenizer.convert_ids_to_tokens(batch[2][0].cpu().numpy()))}')\n",
        "            logger.info(f'Generated: {\"\".join(tokenizer.convert_ids_to_tokens(logits[0].max(-1)[1].cpu().numpy()))}')\n",
        "    \n",
        "    #do save model\n",
        "    if args.output_dir is not None:\n",
        "        state_dict = model.state_dict()\n",
        "        torch.save(state_dict, os.path.join(model_path, 'BertAbsSum_{}.bin'.format(i)))\n",
        "        logger.info('Model saved')\n",
        "    \n",
        "    # do evaluation\n",
        "    if valid_dataloader is not None:\n",
        "        model.eval()\n",
        "        batch = next(iter(valid_dataloader))\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # beam_decode\n",
        "        pred, _ = model.beam_decode(batch[0], batch[1], 3, 3)\n",
        "        # pred = model.greedy_decode(batch[0], batch[1])\n",
        "        logger.info(f'Source: {\"\".join(tokenizer.convert_ids_to_tokens(batch[0][0].cpu().numpy()))}')\n",
        "        logger.info(f'Beam Generated: {\"\".join(tokenizer.convert_ids_to_tokens(pred[0][0]))}')\n",
        "        # logger.info(f'Beam Generated: {tokenizer.convert_ids_to_tokens(pred[0].cpu().numpy())}')\n",
        "    \n",
        "    # do validate        \n",
        "    do_validate()\n",
        "\n",
        "    if args.change_lr:\n",
        "      optimizer.param_groups[0]['lr'] = compute_lr(args.learning_rate,i)\n",
        "      optimizer.param_groups[1]['lr'] = compute_lr(args.learning_rate,i)\n",
        "      logger.info(f'Epoch {i} change lr {optimizer.param_groups[0][\"lr\"]}.')\n",
        "\n",
        "    logger.info(f'Epoch {i} finished.')\n",
        "with open(os.path.join(args.bert_model, 'bert_config.json'), 'r') as f:\n",
        "    bert_config = json.load(f)\n",
        "config = {'bert_config': bert_config, 'decoder_config': decoder_config}\n",
        "with open(os.path.join(model_path, 'config.json'), 'w') as f:\n",
        "    json.dump(config, f)\n",
        "logger.info('Training finished')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/01/2020 08:30:30 - INFO - __main__ -   ***** Running training *****\n",
            "02/01/2020 08:30:30 - INFO - __main__ -     Num examples = 121489\n",
            "02/01/2020 08:30:30 - INFO - __main__ -     Batch size = 48\n",
            "02/01/2020 08:30:30 - INFO - __main__ -     Num steps = 1580\n",
            "Train iter:   4%|▍         | 99/2531 [02:25<1:01:29,  1.52s/it]02/01/2020 08:32:57 - INFO - __main__ -   Epoch 0, step 99, loss 0.31639933586120605. lr 2e-05.\n",
            "02/01/2020 08:32:57 - INFO - __main__ -   Ground: [CLS]theho##lom##or##phyconjectureforidealsindimensiontwo[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 08:32:57 - INFO - __main__ -   Generated: theho##lom##or##phyconjectureforsubinan-[SEP][SEP]----------------\n",
            "Train iter:   8%|▊         | 199/2531 [05:01<1:01:15,  1.58s/it]02/01/2020 08:35:33 - INFO - __main__ -   Epoch 0, step 199, loss 0.28668951988220215. lr 2e-05.\n",
            "02/01/2020 08:35:33 - INFO - __main__ -   Ground: [CLS]lowenergypropertiesofthesu(m|n)super##sy##mme##trichal##dan##e-sha##st##ryspinchain[SEP][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 08:35:33 - INFO - __main__ -   Generated: lowenergyexofthesu(m|n)super##sy##mme##trichal##dan##e-sha##st##ryspinchain[SEP][SEP]---\n",
            "Train iter:  12%|█▏        | 299/2531 [07:41<59:13,  1.59s/it]02/01/2020 08:38:13 - INFO - __main__ -   Epoch 0, step 299, loss 0.3144732415676117. lr 2e-05.\n",
            "02/01/2020 08:38:13 - INFO - __main__ -   Ground: [CLS]st##och##asticintegralrepresentationsofquantummartin##gal##esonmultiplef##ockspace[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 08:38:13 - INFO - __main__ -   Generated: quantum##och##asticintegralrepresentationsformartinmartin##gal##esandmultimartin##gal-andto------------\n",
            "Train iter:  16%|█▌        | 399/2531 [10:20<56:20,  1.59s/it]02/01/2020 08:40:52 - INFO - __main__ -   Epoch 0, step 399, loss 0.29088178277015686. lr 2e-05.\n",
            "02/01/2020 08:40:52 - INFO - __main__ -   Ground: [CLS]res##ona##ntnormalformforevenperiodicf##puchains[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 08:40:52 - INFO - __main__ -   Generated: res##ona##ntnormalformofevenperiodicf##puchains[SEP][SEP]----------------\n",
            "Train iter:  20%|█▉        | 499/2531 [13:00<53:54,  1.59s/it]02/01/2020 08:43:32 - INFO - __main__ -   Epoch 0, step 499, loss 0.2890564501285553. lr 2e-05.\n",
            "02/01/2020 08:43:32 - INFO - __main__ -   Ground: [CLS]apatternmixturemodelforapaired$2\\times##2$crossoverdesign[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 08:43:32 - INFO - __main__ -   Generated: apatternmixturemodelforapaired$2\\times##2$crossoverdesign[SEP]with------------\n",
            "Train iter:  24%|██▎       | 599/2531 [15:40<50:57,  1.58s/it]02/01/2020 08:46:12 - INFO - __main__ -   Epoch 0, step 599, loss 0.2707059383392334. lr 2e-05.\n",
            "02/01/2020 08:46:12 - INFO - __main__ -   Ground: [CLS]generalizedhelm##hol##tz-ki##rch##hoffmodelfortwodimensionaldistributedvortexmotion[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 08:46:12 - INFO - __main__ -   Generated: thehelm##hol##tz-ki##rch##hoffmodelfortwo-vona-[SEP]the------------\n",
            "Train iter:  28%|██▊       | 699/2531 [18:20<48:58,  1.60s/it]02/01/2020 08:48:52 - INFO - __main__ -   Epoch 0, step 699, loss 0.2789251506328583. lr 2e-05.\n",
            "02/01/2020 08:48:52 - INFO - __main__ -   Ground: [CLS]quan##ti##zationbasedfastinnerproductsearch[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 08:48:52 - INFO - __main__ -   Generated: quan##ti##zationbasedfastinnerproductsearch[SEP][SEP]-------------------\n",
            "Train iter:  32%|███▏      | 799/2531 [21:00<45:45,  1.59s/it]02/01/2020 08:51:32 - INFO - __main__ -   Epoch 0, step 799, loss 0.29974400997161865. lr 2e-05.\n",
            "02/01/2020 08:51:32 - INFO - __main__ -   Ground: [CLS]fastcorrelationgreeksbyad##jo##intalgorithm##icdifferentiation[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 08:51:32 - INFO - __main__ -   Generated: efficientcorrelationgreeksofad##jo##intalgorithm##icdifferentiation[SEP][SEP]-----------------\n",
            "Train iter:  36%|███▌      | 899/2531 [23:41<43:26,  1.60s/it]02/01/2020 08:54:12 - INFO - __main__ -   Epoch 0, step 899, loss 0.28748393058776855. lr 2e-05.\n",
            "02/01/2020 08:54:12 - INFO - __main__ -   Ground: [CLS]robustmetriclearningbysmoothoptimization[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 08:54:12 - INFO - __main__ -   Generated: robustmetriclearningbysmoothoptimization[SEP][SEP]---------------------\n",
            "Train iter:  39%|███▉      | 999/2531 [26:20<40:18,  1.58s/it]02/01/2020 08:56:52 - INFO - __main__ -   Epoch 0, step 999, loss 0.24733398854732513. lr 2e-05.\n",
            "02/01/2020 08:56:52 - INFO - __main__ -   Ground: [CLS]comparisonofgall##edtrees[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 08:56:52 - INFO - __main__ -   Generated: comparisonofgall##edtrees[SEP][SEP]----------------------\n",
            "Train iter:  43%|████▎     | 1099/2531 [29:00<37:58,  1.59s/it]02/01/2020 08:59:32 - INFO - __main__ -   Epoch 0, step 1099, loss 0.27956506609916687. lr 2e-05.\n",
            "02/01/2020 08:59:32 - INFO - __main__ -   Ground: [CLS]chargeflu##ct##uationeffectsontheshapeofflexiblepoly##amp##hol##yte##swithapplicationstointrinsic##allydisorder##edproteins[SEP][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 08:59:32 - INFO - __main__ -   Generated: chargepa##ct##uationandontheshapeofdisorderpoly##amp##hol##yte##s[SEP]applicationstodisorderdisorderpolymer[SEP]poly[SEP][SEP]----\n",
            "Train iter:  47%|████▋     | 1199/2531 [31:40<35:07,  1.58s/it]02/01/2020 09:02:12 - INFO - __main__ -   Epoch 0, step 1199, loss 0.2905159890651703. lr 2e-05.\n",
            "02/01/2020 09:02:12 - INFO - __main__ -   Ground: [CLS]coe##xi##sten##ceinanin##hom##ogen##eousenvironment[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:02:12 - INFO - __main__ -   Generated: coe##xi##sten##ceinain##hom##ogen##eousenvironment[SEP]by----------------\n",
            "Train iter:  51%|█████▏    | 1299/2531 [34:20<32:39,  1.59s/it]02/01/2020 09:04:51 - INFO - __main__ -   Epoch 0, step 1299, loss 0.2698719799518585. lr 2e-05.\n",
            "02/01/2020 09:04:51 - INFO - __main__ -   Ground: [CLS]anage-structuredcontinuummodelformy##x##ob##act##eria[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:04:51 - INFO - __main__ -   Generated: aage-structuredmacromodelformy##x##ob##act##eria[SEP][SEP]---------------\n",
            "Train iter:  55%|█████▌    | 1399/2531 [36:59<29:49,  1.58s/it]02/01/2020 09:07:31 - INFO - __main__ -   Epoch 0, step 1399, loss 0.2608247697353363. lr 2e-05.\n",
            "02/01/2020 09:07:31 - INFO - __main__ -   Ground: [CLS]capitalstructureinu.s.,aquan##tileregressionapproachwithmacro##economicimpacts[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:07:31 - INFO - __main__ -   Generated: capitalstructureinu.,.,aquan##tileregressionapproachwithmacro##economicimpacts[SEP][SEP]----------\n",
            "Train iter:  59%|█████▉    | 1499/2531 [39:39<27:17,  1.59s/it]02/01/2020 09:10:11 - INFO - __main__ -   Epoch 0, step 1499, loss 0.27742916345596313. lr 2e-05.\n",
            "02/01/2020 09:10:11 - INFO - __main__ -   Ground: [CLS]amasterequationapproachtooptionpricing[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:10:11 - INFO - __main__ -   Generated: amasterequationapproachtooptionpricing[SEP][SEP]--------------------\n",
            "Train iter:  63%|██████▎   | 1599/2531 [42:18<24:35,  1.58s/it]02/01/2020 09:12:50 - INFO - __main__ -   Epoch 0, step 1599, loss 0.28368905186653137. lr 2e-05.\n",
            "02/01/2020 09:12:50 - INFO - __main__ -   Ground: [CLS]towardimprovingthequalityofdoctoraleducation:afocusonstatistics,researchmethods,anddissertationsupervision[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:12:50 - INFO - __main__ -   Generated: towardimprovingthequalityofdoctoraleducation:afocusonstatistics,researchmethods,andresearchsupervision[SEP][SEP]--------\n",
            "Train iter:  67%|██████▋   | 1699/2531 [44:58<22:07,  1.60s/it]02/01/2020 09:15:30 - INFO - __main__ -   Epoch 0, step 1699, loss 0.27747654914855957. lr 2e-05.\n",
            "02/01/2020 09:15:30 - INFO - __main__ -   Ground: [CLS]localbehaviorofsparseanalysisregular##ization:applicationstoriskestimation[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:15:30 - INFO - __main__ -   Generated: localanalysisofsparseregular:##ization:applicationstoestimationestimation[SEP][SEP]---------------\n",
            "Train iter:  71%|███████   | 1799/2531 [47:38<19:19,  1.58s/it]02/01/2020 09:18:10 - INFO - __main__ -   Epoch 0, step 1799, loss 0.2771419286727905. lr 2e-05.\n",
            "02/01/2020 09:18:10 - INFO - __main__ -   Ground: [CLS]sequencematchingalgorithmsandpairingofnon##co##dingrna##s[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:18:10 - INFO - __main__ -   Generated: alignmentalignmentandandpairingofnon##co##dingrna##s[SEP]energy----------------\n",
            "Train iter:  75%|███████▌  | 1899/2531 [50:18<16:46,  1.59s/it]02/01/2020 09:20:50 - INFO - __main__ -   Epoch 0, step 1899, loss 0.26715895533561707. lr 2e-05.\n",
            "02/01/2020 09:20:50 - INFO - __main__ -   Ground: [CLS]dcapproximationapproachesforsparseoptimization[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:20:50 - INFO - __main__ -   Generated: dcapproximationapproachesforsparseoptimization[SEP]via---------------------\n",
            "Train iter:  79%|███████▉  | 1999/2531 [52:58<13:59,  1.58s/it]02/01/2020 09:23:30 - INFO - __main__ -   Epoch 0, step 1999, loss 0.31230953335762024. lr 2e-05.\n",
            "02/01/2020 09:23:30 - INFO - __main__ -   Ground: [CLS]hybridmethodologyforhourlyglobalradiationforecast##inginmediterraneanarea[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:23:30 - INFO - __main__ -   Generated: hybridmodelfortheradiationradiationforecast##ing[SEP]theenergy[SEP][SEP]----------------\n",
            "Train iter:  83%|████████▎ | 2099/2531 [55:37<11:27,  1.59s/it]02/01/2020 09:26:09 - INFO - __main__ -   Epoch 0, step 2099, loss 0.2869778275489807. lr 2e-05.\n",
            "02/01/2020 09:26:09 - INFO - __main__ -   Ground: [CLS]real-timehighlyaccuratedensedepthonapowerbudgetusinganf##pg##a-cpuhybridsoc[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:26:09 - INFO - __main__ -   Generated: real-timestereodepthdepthdepthusingarealusingusinganf##pg##a-cpupower[SEP][SEP][SEP]-------\n",
            "Train iter:  87%|████████▋ | 2199/2531 [58:17<08:44,  1.58s/it]02/01/2020 09:28:49 - INFO - __main__ -   Epoch 0, step 2199, loss 0.2922001779079437. lr 2e-05.\n",
            "02/01/2020 09:28:49 - INFO - __main__ -   Ground: [CLS]theoriginofinference:ed##iac##aranecologyandtheevolutionofbay##esianbrains[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:28:49 - INFO - __main__ -   Generated: theevolutionofbay:thetototototheevolutionofbay##esiansp[SEP][SEP]-----------\n",
            "Train iter:  91%|█████████ | 2299/2531 [1:00:57<06:09,  1.59s/it]02/01/2020 09:31:29 - INFO - __main__ -   Epoch 0, step 2299, loss 0.3073042631149292. lr 2e-05.\n",
            "02/01/2020 09:31:29 - INFO - __main__ -   Ground: [CLS]detectingcommunitystructuresinhi-cgen##omicdata[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:31:29 - INFO - __main__ -   Generated: detectingcommunitystructuresinhi-c##omic##omicdata[SEP][SEP]-----------------\n",
            "Train iter:  95%|█████████▍| 2399/2531 [1:03:37<03:28,  1.58s/it]02/01/2020 09:34:09 - INFO - __main__ -   Epoch 0, step 2399, loss 0.30619755387306213. lr 2e-05.\n",
            "02/01/2020 09:34:09 - INFO - __main__ -   Ground: [CLS]comment:micro##ar##ray##s,empiricalbay##esandthetwo-groupsmodel[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:34:09 - INFO - __main__ -   Generated: comment:micro##ar##ray##s,empiricalbay##esandthetwo-groupsmodel[SEP][SEP]-----------\n",
            "Train iter:  99%|█████████▊| 2499/2531 [1:06:17<00:50,  1.59s/it]02/01/2020 09:36:49 - INFO - __main__ -   Epoch 0, step 2499, loss 0.32120877504348755. lr 2e-05.\n",
            "02/01/2020 09:36:49 - INFO - __main__ -   Ground: [CLS]analternativeproofofaresultoftak##ao##ka[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:36:49 - INFO - __main__ -   Generated: onproofproofoftaktakoftak##ae##ka'under-----------------\n",
            "Train iter: 100%|██████████| 2531/2531 [1:07:08<00:00,  1.60s/it]\n",
            "02/01/2020 09:37:41 - INFO - __main__ -   Model saved\n",
            "02/01/2020 09:37:45 - INFO - __main__ -   Source: [CLS]thisworktreatsonthequestionwhetheragivenmapf:m->bofsmoothclosedmanifold##sishomo##top##ictoasmoothfiberbundle.wedefineafirstobstructioninh^1(b;w##h(\\pi_1(e)))and,providedthatthisobstructionvanish##esandoneadditionalconditionisverified,asecondobstructioninw##h(\\pi_1(e))>.bothelementsvanishiftheanswertotheabovequestionispositive.inthecasewherebisthe1-sphereandthedimensionofmexceedsfive,weshowthattheconverseisalsotrue,using[SEP]\n",
            "02/01/2020 09:37:45 - INFO - __main__ -   Beam Generated: theobstructionofsmoothfiberbundles[SEP]\n",
            "02/01/2020 09:37:45 - INFO - __main__ -   ***** Running validation *****\n",
            "Val iter: 100%|██████████| 281/281 [19:02<00:00,  4.01s/it]\n",
            "02/01/2020 09:56:48 - INFO - __main__ -   ******Validation results******\n",
            "02/01/2020 09:56:48 - INFO - __main__ -   beam_size: 3 n_best: 3 Rouge-1: 0.7431550996022127 Rouge-2: 0.594515688525734\n",
            "02/01/2020 09:56:48 - INFO - __main__ -   Validation finished.\n",
            "02/01/2020 09:56:48 - INFO - __main__ -   Epoch 0 change lr 2e-05.\n",
            "02/01/2020 09:56:48 - INFO - __main__ -   Epoch 0 finished.\n",
            "Train iter:   4%|▍         | 99/2531 [02:38<1:04:37,  1.59s/it]02/01/2020 09:59:27 - INFO - __main__ -   Epoch 1, step 99, loss 0.3109467923641205. lr 2e-05.\n",
            "02/01/2020 09:59:28 - INFO - __main__ -   Ground: [CLS]theho##lom##or##phyconjectureforidealsindimensiontwo[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 09:59:28 - INFO - __main__ -   Generated: theho##lom##or##phyconjectureforhyperintwo-[SEP][SEP]----------------\n",
            "Train iter:   8%|▊         | 199/2531 [05:17<1:01:31,  1.58s/it]02/01/2020 10:02:07 - INFO - __main__ -   Epoch 1, step 199, loss 0.27898845076560974. lr 2e-05.\n",
            "02/01/2020 10:02:07 - INFO - __main__ -   Ground: [CLS]lowenergypropertiesofthesu(m|n)super##sy##mme##trichal##dan##e-sha##st##ryspinchain[SEP][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:02:07 - INFO - __main__ -   Generated: lowenergystatesofthesu(m|n)super##sy##mme##trichal##dan##e-sha##st##ryspinchain[SEP]chain---\n",
            "Train iter:  12%|█▏        | 299/2531 [07:57<59:14,  1.59s/it]02/01/2020 10:04:47 - INFO - __main__ -   Epoch 1, step 299, loss 0.29963430762290955. lr 2e-05.\n",
            "02/01/2020 10:04:47 - INFO - __main__ -   Ground: [CLS]st##och##asticintegralrepresentationsofquantummartin##gal##esonmultiplef##ockspace[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:04:47 - INFO - __main__ -   Generated: quantum##och##asticintegralrepresentationsofmartinmartin##gal##esinmultimartin##gal-[SEP]to------------\n",
            "Train iter:  16%|█▌        | 399/2531 [10:37<56:25,  1.59s/it]02/01/2020 10:07:27 - INFO - __main__ -   Epoch 1, step 399, loss 0.2743343412876129. lr 2e-05.\n",
            "02/01/2020 10:07:27 - INFO - __main__ -   Ground: [CLS]res##ona##ntnormalformforevenperiodicf##puchains[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:07:27 - INFO - __main__ -   Generated: res##ona##ntnormalformofevenperiodicf##puchains[SEP][SEP]----------------\n",
            "Train iter:  20%|█▉        | 499/2531 [13:17<53:57,  1.59s/it]02/01/2020 10:10:06 - INFO - __main__ -   Epoch 1, step 499, loss 0.27277621626853943. lr 2e-05.\n",
            "02/01/2020 10:10:06 - INFO - __main__ -   Ground: [CLS]apatternmixturemodelforapaired$2\\times##2$crossoverdesign[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:10:06 - INFO - __main__ -   Generated: apatternmixturemodelforapaired$2\\times##2$crossoverdesign[SEP]with------------\n",
            "Train iter:  24%|██▎       | 599/2531 [15:56<50:54,  1.58s/it]02/01/2020 10:12:46 - INFO - __main__ -   Epoch 1, step 599, loss 0.2583000957965851. lr 2e-05.\n",
            "02/01/2020 10:12:46 - INFO - __main__ -   Ground: [CLS]generalizedhelm##hol##tz-ki##rch##hoffmodelfortwodimensionaldistributedvortexmotion[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:12:46 - INFO - __main__ -   Generated: geometrichelm##hol##tz-ki##rch##hoffmodelfortwo-twotwo-[SEP]the------------\n",
            "Train iter:  28%|██▊       | 699/2531 [18:36<48:33,  1.59s/it]02/01/2020 10:15:26 - INFO - __main__ -   Epoch 1, step 699, loss 0.25735437870025635. lr 2e-05.\n",
            "02/01/2020 10:15:26 - INFO - __main__ -   Ground: [CLS]quan##ti##zationbasedfastinnerproductsearch[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:15:26 - INFO - __main__ -   Generated: quan##ti##zationbasedfastinnerproductsearch[SEP][SEP]-------------------\n",
            "Train iter:  32%|███▏      | 799/2531 [21:15<45:37,  1.58s/it]02/01/2020 10:18:05 - INFO - __main__ -   Epoch 1, step 799, loss 0.2771012485027313. lr 2e-05.\n",
            "02/01/2020 10:18:05 - INFO - __main__ -   Ground: [CLS]fastcorrelationgreeksbyad##jo##intalgorithm##icdifferentiation[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:18:05 - INFO - __main__ -   Generated: fastcorrelationgreeksbyad##jo##intalgorithm##icdifferentiation[SEP][SEP]-----------------\n",
            "Train iter:  36%|███▌      | 899/2531 [23:55<43:28,  1.60s/it]02/01/2020 10:20:45 - INFO - __main__ -   Epoch 1, step 899, loss 0.26386958360671997. lr 2e-05.\n",
            "02/01/2020 10:20:45 - INFO - __main__ -   Ground: [CLS]robustmetriclearningbysmoothoptimization[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:20:45 - INFO - __main__ -   Generated: robustmetriclearningbysmoothoptimization[SEP][SEP]---------------------\n",
            "Train iter:  39%|███▉      | 999/2531 [26:35<40:18,  1.58s/it]02/01/2020 10:23:25 - INFO - __main__ -   Epoch 1, step 999, loss 0.22904734313488007. lr 2e-05.\n",
            "02/01/2020 10:23:25 - INFO - __main__ -   Ground: [CLS]comparisonofgall##edtrees[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:23:25 - INFO - __main__ -   Generated: comparisonofgall##edtrees[SEP][SEP]----------------------\n",
            "Train iter:  43%|████▎     | 1099/2531 [29:14<38:02,  1.59s/it]02/01/2020 10:26:04 - INFO - __main__ -   Epoch 1, step 1099, loss 0.2549411356449127. lr 2e-05.\n",
            "02/01/2020 10:26:04 - INFO - __main__ -   Ground: [CLS]chargeflu##ct##uationeffectsontheshapeofflexiblepoly##amp##hol##yte##swithapplicationstointrinsic##allydisorder##edproteins[SEP][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:26:04 - INFO - __main__ -   Generated: chargeflu##ct##uationeffectsontheshapeofrandomlypoly##amp##hol##yte##s[SEP]applicationstodisorderdisorderpolymer##edpolymer[SEP][SEP]----\n",
            "Train iter:  47%|████▋     | 1199/2531 [31:54<35:05,  1.58s/it]02/01/2020 10:28:44 - INFO - __main__ -   Epoch 1, step 1199, loss 0.2655794620513916. lr 2e-05.\n",
            "02/01/2020 10:28:44 - INFO - __main__ -   Ground: [CLS]coe##xi##sten##ceinanin##hom##ogen##eousenvironment[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:28:44 - INFO - __main__ -   Generated: coe##xi##sten##ceinanin##hom##ogen##eousenvironment[SEP]by----------------\n",
            "Train iter:  51%|█████▏    | 1299/2531 [34:33<32:35,  1.59s/it]02/01/2020 10:31:23 - INFO - __main__ -   Epoch 1, step 1299, loss 0.24621079862117767. lr 2e-05.\n",
            "02/01/2020 10:31:23 - INFO - __main__ -   Ground: [CLS]anage-structuredcontinuummodelformy##x##ob##act##eria[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:31:23 - INFO - __main__ -   Generated: anage-structuredmacromodelformy##x##ob##act##eria[SEP][SEP]---------------\n",
            "Train iter:  55%|█████▌    | 1399/2531 [37:13<29:54,  1.59s/it]02/01/2020 10:34:03 - INFO - __main__ -   Epoch 1, step 1399, loss 0.2390027493238449. lr 2e-05.\n",
            "02/01/2020 10:34:03 - INFO - __main__ -   Ground: [CLS]capitalstructureinu.s.,aquan##tileregressionapproachwithmacro##economicimpacts[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:34:03 - INFO - __main__ -   Generated: capitalstructureinu.s.,aquan##tileregressionapproachwithmacro##economicimpacts[SEP][SEP]----------\n",
            "Train iter:  59%|█████▉    | 1499/2531 [39:53<27:21,  1.59s/it]02/01/2020 10:36:42 - INFO - __main__ -   Epoch 1, step 1499, loss 0.25376102328300476. lr 2e-05.\n",
            "02/01/2020 10:36:42 - INFO - __main__ -   Ground: [CLS]amasterequationapproachtooptionpricing[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:36:42 - INFO - __main__ -   Generated: amasterequationapproachtooptionpricing[SEP][SEP]--------------------\n",
            "Train iter:  63%|██████▎   | 1599/2531 [42:32<24:32,  1.58s/it]02/01/2020 10:39:22 - INFO - __main__ -   Epoch 1, step 1599, loss 0.259976863861084. lr 2e-05.\n",
            "02/01/2020 10:39:22 - INFO - __main__ -   Ground: [CLS]towardimprovingthequalityofdoctoraleducation:afocusonstatistics,researchmethods,anddissertationsupervision[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:39:22 - INFO - __main__ -   Generated: towardimprovingthequalityofdoctoraleducation:afocusonstatistics,researchmethods,andresearchsupervision[SEP][SEP]--------\n",
            "Train iter:  67%|██████▋   | 1699/2531 [45:12<22:04,  1.59s/it]02/01/2020 10:42:02 - INFO - __main__ -   Epoch 1, step 1699, loss 0.2556348145008087. lr 2e-05.\n",
            "02/01/2020 10:42:02 - INFO - __main__ -   Ground: [CLS]localbehaviorofsparseanalysisregular##ization:applicationstoriskestimation[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:42:02 - INFO - __main__ -   Generated: localanalysisofsparseanalysis:##ization:applicationstoestimationestimation[SEP][SEP]---------------\n",
            "Train iter:  71%|███████   | 1799/2531 [47:52<19:15,  1.58s/it]02/01/2020 10:44:41 - INFO - __main__ -   Epoch 1, step 1799, loss 0.2531222403049469. lr 2e-05.\n",
            "02/01/2020 10:44:41 - INFO - __main__ -   Ground: [CLS]sequencematchingalgorithmsandpairingofnon##co##dingrna##s[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:44:41 - INFO - __main__ -   Generated: sequencematchingandandpairingofnon##co##dingrna##s[SEP]energy----------------\n",
            "Train iter:  75%|███████▌  | 1899/2531 [50:31<16:48,  1.60s/it]02/01/2020 10:47:21 - INFO - __main__ -   Epoch 1, step 1899, loss 0.24567291140556335. lr 2e-05.\n",
            "02/01/2020 10:47:21 - INFO - __main__ -   Ground: [CLS]dcapproximationapproachesforsparseoptimization[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:47:21 - INFO - __main__ -   Generated: dcapproximationapproachesforsparseoptimization[SEP]via---------------------\n",
            "Train iter:  79%|███████▉  | 1999/2531 [53:11<14:01,  1.58s/it]02/01/2020 10:50:01 - INFO - __main__ -   Epoch 1, step 1999, loss 0.2799346148967743. lr 2e-05.\n",
            "02/01/2020 10:50:01 - INFO - __main__ -   Ground: [CLS]hybridmethodologyforhourlyglobalradiationforecast##inginmediterraneanarea[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:50:01 - INFO - __main__ -   Generated: hybridforecastfortheradiationradiationforecast##inginmediterraneanenergy[SEP]the----------------\n",
            "Train iter:  83%|████████▎ | 2099/2531 [55:51<11:29,  1.60s/it]02/01/2020 10:52:41 - INFO - __main__ -   Epoch 1, step 2099, loss 0.2597613036632538. lr 2e-05.\n",
            "02/01/2020 10:52:41 - INFO - __main__ -   Ground: [CLS]real-timehighlyaccuratedensedepthonapowerbudgetusinganf##pg##a-cpuhybridsoc[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:52:41 - INFO - __main__ -   Generated: real-timestereoaccuratedepthdepthonafusingusinganf##pg##a-cpucpuoptimization[SEP][SEP]-------\n",
            "Train iter:  87%|████████▋ | 2199/2531 [58:31<08:44,  1.58s/it]02/01/2020 10:55:21 - INFO - __main__ -   Epoch 1, step 2199, loss 0.26367008686065674. lr 2e-05.\n",
            "02/01/2020 10:55:21 - INFO - __main__ -   Ground: [CLS]theoriginofinference:ed##iac##aranecologyandtheevolutionofbay##esianbrains[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:55:21 - INFO - __main__ -   Generated: theevolutionofbay:theecology,,andtheevolutionofbay##esiansp[SEP]##ng-----------\n",
            "Train iter:  91%|█████████ | 2299/2531 [1:01:11<06:08,  1.59s/it]02/01/2020 10:58:00 - INFO - __main__ -   Epoch 1, step 2299, loss 0.27912598848342896. lr 2e-05.\n",
            "02/01/2020 10:58:00 - INFO - __main__ -   Ground: [CLS]detectingcommunitystructuresinhi-cgen##omicdata[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 10:58:00 - INFO - __main__ -   Generated: detectingcommunitystructuresinhi-cgen##omicdata[SEP][SEP]-----------------\n",
            "Train iter:  95%|█████████▍| 2399/2531 [1:03:50<03:28,  1.58s/it]02/01/2020 11:00:40 - INFO - __main__ -   Epoch 1, step 2399, loss 0.2773319482803345. lr 2e-05.\n",
            "02/01/2020 11:00:40 - INFO - __main__ -   Ground: [CLS]comment:micro##ar##ray##s,empiricalbay##esandthetwo-groupsmodel[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:00:40 - INFO - __main__ -   Generated: comment:micro##ar##ray##s,empiricalbay##esandthetwo-groupsmodel[SEP][SEP]-----------\n",
            "Train iter:  99%|█████████▊| 2499/2531 [1:06:30<00:50,  1.59s/it]02/01/2020 11:03:20 - INFO - __main__ -   Epoch 1, step 2499, loss 0.285690039396286. lr 2e-05.\n",
            "02/01/2020 11:03:20 - INFO - __main__ -   Ground: [CLS]analternativeproofofaresultoftak##ao##ka[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:03:20 - INFO - __main__ -   Generated: anproofproofofatakoftakprocesses##ka[SEP]under-----------------\n",
            "Train iter: 100%|██████████| 2531/2531 [1:07:21<00:00,  1.59s/it]\n",
            "02/01/2020 11:04:12 - INFO - __main__ -   Model saved\n",
            "02/01/2020 11:04:16 - INFO - __main__ -   Source: [CLS]thisworktreatsonthequestionwhetheragivenmapf:m->bofsmoothclosedmanifold##sishomo##top##ictoasmoothfiberbundle.wedefineafirstobstructioninh^1(b;w##h(\\pi_1(e)))and,providedthatthisobstructionvanish##esandoneadditionalconditionisverified,asecondobstructioninw##h(\\pi_1(e))>.bothelementsvanishiftheanswertotheabovequestionispositive.inthecasewherebisthe1-sphereandthedimensionofmexceedsfive,weshowthattheconverseisalsotrue,using[SEP]\n",
            "02/01/2020 11:04:16 - INFO - __main__ -   Beam Generated: theobstructionoffiberbundles[SEP]\n",
            "02/01/2020 11:04:16 - INFO - __main__ -   ***** Running validation *****\n",
            "Val iter: 100%|██████████| 281/281 [19:33<00:00,  4.08s/it]\n",
            "02/01/2020 11:23:50 - INFO - __main__ -   ******Validation results******\n",
            "02/01/2020 11:23:50 - INFO - __main__ -   beam_size: 3 n_best: 3 Rouge-1: 0.7479972888682561 Rouge-2: 0.5979437375466493\n",
            "02/01/2020 11:23:50 - INFO - __main__ -   Validation finished.\n",
            "02/01/2020 11:23:50 - INFO - __main__ -   Epoch 1 change lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:23:50 - INFO - __main__ -   Epoch 1 finished.\n",
            "Train iter:   4%|▍         | 99/2531 [02:37<1:04:23,  1.59s/it]02/01/2020 11:26:30 - INFO - __main__ -   Epoch 2, step 99, loss 0.2838664650917053. lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:26:30 - INFO - __main__ -   Ground: [CLS]theho##lom##or##phyconjectureforidealsindimensiontwo[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:26:30 - INFO - __main__ -   Generated: theho##lom##or##phyconjectureforhyperintwo-the[SEP]----------------\n",
            "Train iter:   8%|▊         | 199/2531 [05:17<1:01:30,  1.58s/it]02/01/2020 11:29:09 - INFO - __main__ -   Epoch 2, step 199, loss 0.2585052251815796. lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:29:09 - INFO - __main__ -   Ground: [CLS]lowenergypropertiesofthesu(m|n)super##sy##mme##trichal##dan##e-sha##st##ryspinchain[SEP][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:29:09 - INFO - __main__ -   Generated: lowenergyandofthesu(m|n)super##sy##mme##trichal##dan##e-sha##st##ryspinchain[SEP][SEP]---\n",
            "Train iter:  12%|█▏        | 299/2531 [07:57<59:20,  1.59s/it]02/01/2020 11:31:49 - INFO - __main__ -   Epoch 2, step 299, loss 0.2746129333972931. lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:31:49 - INFO - __main__ -   Ground: [CLS]st##och##asticintegralrepresentationsofquantummartin##gal##esonmultiplef##ockspace[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:31:49 - INFO - __main__ -   Generated: quantum##och##asticintegralrepresentationsofquantummartin##gal##esonmultimartin##gal-[SEP]to------------\n",
            "Train iter:  16%|█▌        | 399/2531 [10:36<56:16,  1.58s/it]02/01/2020 11:34:28 - INFO - __main__ -   Epoch 2, step 399, loss 0.2544536590576172. lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:34:28 - INFO - __main__ -   Ground: [CLS]res##ona##ntnormalformforevenperiodicf##puchains[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:34:28 - INFO - __main__ -   Generated: res##ona##ntnormalformofevenperiodicf##puchains[SEP][SEP]----------------\n",
            "Train iter:  20%|█▉        | 499/2531 [13:16<53:52,  1.59s/it]02/01/2020 11:37:08 - INFO - __main__ -   Epoch 2, step 499, loss 0.25505414605140686. lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:37:08 - INFO - __main__ -   Ground: [CLS]apatternmixturemodelforapaired$2\\times##2$crossoverdesign[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:37:08 - INFO - __main__ -   Generated: apatternmixturemodelforapaired$2\\times##2$crossoverdesign[SEP]with------------\n",
            "Train iter:  24%|██▎       | 599/2531 [15:55<50:43,  1.58s/it]02/01/2020 11:39:47 - INFO - __main__ -   Epoch 2, step 599, loss 0.2450188398361206. lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:39:47 - INFO - __main__ -   Ground: [CLS]generalizedhelm##hol##tz-ki##rch##hoffmodelfortwodimensionaldistributedvortexmotion[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:39:47 - INFO - __main__ -   Generated: generalizedhelm##hol##tz-ki##rch##hoffmodelfortwodimensionalvovoflows[SEP]the------------\n",
            "Train iter:  28%|██▊       | 699/2531 [18:35<48:36,  1.59s/it]02/01/2020 11:42:27 - INFO - __main__ -   Epoch 2, step 699, loss 0.2414214015007019. lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:42:27 - INFO - __main__ -   Ground: [CLS]quan##ti##zationbasedfastinnerproductsearch[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:42:27 - INFO - __main__ -   Generated: quan##ti##zationbasedfastinnerproductsearch[SEP][SEP]-------------------\n",
            "Train iter:  32%|███▏      | 799/2531 [21:14<45:38,  1.58s/it]02/01/2020 11:45:07 - INFO - __main__ -   Epoch 2, step 799, loss 0.2593575119972229. lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:45:07 - INFO - __main__ -   Ground: [CLS]fastcorrelationgreeksbyad##jo##intalgorithm##icdifferentiation[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:45:07 - INFO - __main__ -   Generated: fastcorrelationgreeksbyad##jo##intalgorithm##icdifferentiation[SEP][SEP]-----------------\n",
            "Train iter:  36%|███▌      | 899/2531 [23:54<43:21,  1.59s/it]02/01/2020 11:47:46 - INFO - __main__ -   Epoch 2, step 899, loss 0.24868491291999817. lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:47:46 - INFO - __main__ -   Ground: [CLS]robustmetriclearningbysmoothoptimization[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:47:46 - INFO - __main__ -   Generated: robustmetriclearningbysmoothoptimization[SEP][SEP]---------------------\n",
            "Train iter:  39%|███▉      | 999/2531 [26:34<40:21,  1.58s/it]02/01/2020 11:50:26 - INFO - __main__ -   Epoch 2, step 999, loss 0.21567094326019287. lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:50:26 - INFO - __main__ -   Ground: [CLS]comparisonofgall##edtrees[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:50:26 - INFO - __main__ -   Generated: comparisonofgall##edtrees[SEP][SEP]----------------------\n",
            "Train iter:  43%|████▎     | 1099/2531 [29:14<38:02,  1.59s/it]02/01/2020 11:53:06 - INFO - __main__ -   Epoch 2, step 1099, loss 0.23864980041980743. lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:53:06 - INFO - __main__ -   Ground: [CLS]chargeflu##ct##uationeffectsontheshapeofflexiblepoly##amp##hol##yte##swithapplicationstointrinsic##allydisorder##edproteins[SEP][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:53:06 - INFO - __main__ -   Generated: chargeflu##ct##uationeffectsontheshapeofflexiblepoly##amp##hol##yte##s[SEP]applicationstodisorder##allypolymer##edpolymer[SEP][SEP]----\n",
            "Train iter:  47%|████▋     | 1199/2531 [31:54<35:05,  1.58s/it]02/01/2020 11:55:46 - INFO - __main__ -   Epoch 2, step 1199, loss 0.2487623691558838. lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:55:46 - INFO - __main__ -   Ground: [CLS]coe##xi##sten##ceinanin##hom##ogen##eousenvironment[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:55:46 - INFO - __main__ -   Generated: coe##xi##sten##ceinanin##hom##ogen##eousenvironment[SEP]competition----------------\n",
            "Train iter:  51%|█████▏    | 1299/2531 [34:34<32:40,  1.59s/it]02/01/2020 11:58:26 - INFO - __main__ -   Epoch 2, step 1299, loss 0.23406179249286652. lr 1.6000000000000003e-05.\n",
            "02/01/2020 11:58:26 - INFO - __main__ -   Ground: [CLS]anage-structuredcontinuummodelformy##x##ob##act##eria[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 11:58:26 - INFO - __main__ -   Generated: anage-structuredmacromodelformy##x##ob##act##eria[SEP][SEP]---------------\n",
            "Train iter:  55%|█████▌    | 1399/2531 [37:13<29:51,  1.58s/it]02/01/2020 12:01:06 - INFO - __main__ -   Epoch 2, step 1399, loss 0.226955384016037. lr 1.6000000000000003e-05.\n",
            "02/01/2020 12:01:06 - INFO - __main__ -   Ground: [CLS]capitalstructureinu.s.,aquan##tileregressionapproachwithmacro##economicimpacts[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:01:06 - INFO - __main__ -   Generated: capitalstructureinu.s.,aquan##tileregressionapproachwithmacro##economicimpacts[SEP][SEP]----------\n",
            "Train iter:  59%|█████▉    | 1499/2531 [39:53<27:23,  1.59s/it]02/01/2020 12:03:45 - INFO - __main__ -   Epoch 2, step 1499, loss 0.23843687772750854. lr 1.6000000000000003e-05.\n",
            "02/01/2020 12:03:45 - INFO - __main__ -   Ground: [CLS]amasterequationapproachtooptionpricing[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:03:45 - INFO - __main__ -   Generated: amasterequationapproachtooptionpricing[SEP][SEP]--------------------\n",
            "Train iter:  63%|██████▎   | 1599/2531 [42:33<24:32,  1.58s/it]02/01/2020 12:06:25 - INFO - __main__ -   Epoch 2, step 1599, loss 0.24354244768619537. lr 1.6000000000000003e-05.\n",
            "02/01/2020 12:06:25 - INFO - __main__ -   Ground: [CLS]towardimprovingthequalityofdoctoraleducation:afocusonstatistics,researchmethods,anddissertationsupervision[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:06:25 - INFO - __main__ -   Generated: towardimprovingthequalityofdoctoraleducation:afocusonstatistics,researchmethods,andresearchsupervision[SEP][SEP]--------\n",
            "Train iter:  67%|██████▋   | 1699/2531 [45:12<22:00,  1.59s/it]02/01/2020 12:09:04 - INFO - __main__ -   Epoch 2, step 1699, loss 0.240991473197937. lr 1.6000000000000003e-05.\n",
            "02/01/2020 12:09:04 - INFO - __main__ -   Ground: [CLS]localbehaviorofsparseanalysisregular##ization:applicationstoriskestimation[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:09:05 - INFO - __main__ -   Generated: localanalysisofsparseanalysis:##ization:applicationstoriskestimation[SEP][SEP]---------------\n",
            "Train iter:  71%|███████   | 1799/2531 [47:52<19:18,  1.58s/it]02/01/2020 12:11:44 - INFO - __main__ -   Epoch 2, step 1799, loss 0.23863157629966736. lr 1.6000000000000003e-05.\n",
            "02/01/2020 12:11:44 - INFO - __main__ -   Ground: [CLS]sequencematchingalgorithmsandpairingofnon##co##dingrna##s[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:11:44 - INFO - __main__ -   Generated: sequencematchingandandpairingofnon##co##dingrna##s[SEP]energy----------------\n",
            "Train iter:  75%|███████▌  | 1899/2531 [50:32<16:50,  1.60s/it]02/01/2020 12:14:24 - INFO - __main__ -   Epoch 2, step 1899, loss 0.23321276903152466. lr 1.6000000000000003e-05.\n",
            "02/01/2020 12:14:24 - INFO - __main__ -   Ground: [CLS]dcapproximationapproachesforsparseoptimization[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:14:24 - INFO - __main__ -   Generated: dcapproximationapproachesforsparseoptimization[SEP]via---------------------\n",
            "Train iter:  79%|███████▉  | 1999/2531 [53:12<14:03,  1.58s/it]02/01/2020 12:17:05 - INFO - __main__ -   Epoch 2, step 1999, loss 0.26578226685523987. lr 1.6000000000000003e-05.\n",
            "02/01/2020 12:17:05 - INFO - __main__ -   Ground: [CLS]hybridmethodologyforhourlyglobalradiationforecast##inginmediterraneanarea[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:17:05 - INFO - __main__ -   Generated: hybridmodelsfortheglobalradiationforecast##inginmediterraneanenergy[SEP]the----------------\n",
            "Train iter:  83%|████████▎ | 2099/2531 [55:52<11:27,  1.59s/it]02/01/2020 12:19:44 - INFO - __main__ -   Epoch 2, step 2099, loss 0.24553239345550537. lr 1.6000000000000003e-05.\n",
            "02/01/2020 12:19:44 - INFO - __main__ -   Ground: [CLS]real-timehighlyaccuratedensedepthonapowerbudgetusinganf##pg##a-cpuhybridsoc[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:19:44 - INFO - __main__ -   Generated: real-timestereoaccuratedepthdepthonarealusingusinganf##pg##a-cpupower[SEP][SEP][SEP]-------\n",
            "Train iter:  87%|████████▋ | 2199/2531 [58:31<08:44,  1.58s/it]02/01/2020 12:22:24 - INFO - __main__ -   Epoch 2, step 2199, loss 0.24924686551094055. lr 1.6000000000000003e-05.\n",
            "02/01/2020 12:22:24 - INFO - __main__ -   Ground: [CLS]theoriginofinference:ed##iac##aranecologyandtheevolutionofbay##esianbrains[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:22:24 - INFO - __main__ -   Generated: theevolutionofinference:theecology,,andtheevolutionofbay##esiansp[SEP][SEP]-----------\n",
            "Train iter:  91%|█████████ | 2299/2531 [1:01:11<06:08,  1.59s/it]02/01/2020 12:25:03 - INFO - __main__ -   Epoch 2, step 2299, loss 0.25944873690605164. lr 1.6000000000000003e-05.\n",
            "02/01/2020 12:25:03 - INFO - __main__ -   Ground: [CLS]detectingcommunitystructuresinhi-cgen##omicdata[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:25:03 - INFO - __main__ -   Generated: detectingcommunitystructuresinhi-cgen##omicdata[SEP][SEP]-----------------\n",
            "Train iter:  95%|█████████▍| 2399/2531 [1:03:51<03:28,  1.58s/it]02/01/2020 12:27:43 - INFO - __main__ -   Epoch 2, step 2399, loss 0.25990596413612366. lr 1.6000000000000003e-05.\n",
            "02/01/2020 12:27:43 - INFO - __main__ -   Ground: [CLS]comment:micro##ar##ray##s,empiricalbay##esandthetwo-groupsmodel[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:27:43 - INFO - __main__ -   Generated: comment:micro##ar##ray##s,empiricalbay##esandthetwo-groupsmodel[SEP][SEP]-----------\n",
            "Train iter:  99%|█████████▊| 2499/2531 [1:06:31<00:50,  1.59s/it]02/01/2020 12:30:23 - INFO - __main__ -   Epoch 2, step 2499, loss 0.26918548345565796. lr 1.6000000000000003e-05.\n",
            "02/01/2020 12:30:23 - INFO - __main__ -   Ground: [CLS]analternativeproofofaresultoftak##ao##ka[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:30:23 - INFO - __main__ -   Generated: anproofproofofatakoftak##ae##ka[SEP]under-----------------\n",
            "Train iter: 100%|██████████| 2531/2531 [1:07:22<00:00,  1.60s/it]\n",
            "02/01/2020 12:31:15 - INFO - __main__ -   Model saved\n",
            "02/01/2020 12:31:19 - INFO - __main__ -   Source: [CLS]thisworktreatsonthequestionwhetheragivenmapf:m->bofsmoothclosedmanifold##sishomo##top##ictoasmoothfiberbundle.wedefineafirstobstructioninh^1(b;w##h(\\pi_1(e)))and,providedthatthisobstructionvanish##esandoneadditionalconditionisverified,asecondobstructioninw##h(\\pi_1(e))>.bothelementsvanishiftheanswertotheabovequestionispositive.inthecasewherebisthe1-sphereandthedimensionofmexceedsfive,weshowthattheconverseisalsotrue,using[SEP]\n",
            "02/01/2020 12:31:19 - INFO - __main__ -   Beam Generated: theobstructionoffiberbundles[SEP]\n",
            "02/01/2020 12:31:19 - INFO - __main__ -   ***** Running validation *****\n",
            "Val iter: 100%|██████████| 281/281 [18:49<00:00,  4.03s/it]\n",
            "02/01/2020 12:50:09 - INFO - __main__ -   ******Validation results******\n",
            "02/01/2020 12:50:09 - INFO - __main__ -   beam_size: 3 n_best: 3 Rouge-1: 0.7389415809521276 Rouge-2: 0.5918866193827599\n",
            "02/01/2020 12:50:09 - INFO - __main__ -   Validation finished.\n",
            "02/01/2020 12:50:09 - INFO - __main__ -   Epoch 2 change lr 1.2e-05.\n",
            "02/01/2020 12:50:09 - INFO - __main__ -   Epoch 2 finished.\n",
            "Train iter:   4%|▍         | 99/2531 [02:37<1:04:25,  1.59s/it]02/01/2020 12:52:48 - INFO - __main__ -   Epoch 3, step 99, loss 0.26827284693717957. lr 1.2e-05.\n",
            "02/01/2020 12:52:48 - INFO - __main__ -   Ground: [CLS]theho##lom##or##phyconjectureforidealsindimensiontwo[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:52:48 - INFO - __main__ -   Generated: theho##lom##or##phyconjectureforidealsintwo-[SEP][SEP]----------------\n",
            "Train iter:   8%|▊         | 199/2531 [05:17<1:01:27,  1.58s/it]02/01/2020 12:55:28 - INFO - __main__ -   Epoch 3, step 199, loss 0.2461140900850296. lr 1.2e-05.\n",
            "02/01/2020 12:55:28 - INFO - __main__ -   Ground: [CLS]lowenergypropertiesofthesu(m|n)super##sy##mme##trichal##dan##e-sha##st##ryspinchain[SEP][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:55:28 - INFO - __main__ -   Generated: lowenergypropertiesofthesu(m|n)super##sy##mme##trichal##dan##e-sha##st##ryspinchain[SEP][SEP]---\n",
            "Train iter:  12%|█▏        | 299/2531 [07:57<59:27,  1.60s/it]02/01/2020 12:58:08 - INFO - __main__ -   Epoch 3, step 299, loss 0.261732280254364. lr 1.2e-05.\n",
            "02/01/2020 12:58:08 - INFO - __main__ -   Ground: [CLS]st##och##asticintegralrepresentationsofquantummartin##gal##esonmultiplef##ockspace[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 12:58:08 - INFO - __main__ -   Generated: quantum##och##asticintegralrepresentationsofquantummartin##gal##esonmultif##ockspace[SEP]to------------\n",
            "Train iter:  16%|█▌        | 399/2531 [10:36<56:30,  1.59s/it]02/01/2020 13:00:48 - INFO - __main__ -   Epoch 3, step 399, loss 0.24412280321121216. lr 1.2e-05.\n",
            "02/01/2020 13:00:48 - INFO - __main__ -   Ground: [CLS]res##ona##ntnormalformforevenperiodicf##puchains[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:00:48 - INFO - __main__ -   Generated: res##ona##ntnormalformforevenperiodicf##puchains[SEP][SEP]----------------\n",
            "Train iter:  20%|█▉        | 499/2531 [13:16<54:01,  1.60s/it]02/01/2020 13:03:27 - INFO - __main__ -   Epoch 3, step 499, loss 0.24479921162128448. lr 1.2e-05.\n",
            "02/01/2020 13:03:27 - INFO - __main__ -   Ground: [CLS]apatternmixturemodelforapaired$2\\times##2$crossoverdesign[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:03:27 - INFO - __main__ -   Generated: apatternmixturemodelforapaired$2\\times##2$crossoverdesign[SEP]with------------\n",
            "Train iter:  24%|██▎       | 599/2531 [15:56<50:54,  1.58s/it]02/01/2020 13:06:08 - INFO - __main__ -   Epoch 3, step 599, loss 0.2330189049243927. lr 1.2e-05.\n",
            "02/01/2020 13:06:08 - INFO - __main__ -   Ground: [CLS]generalizedhelm##hol##tz-ki##rch##hoffmodelfortwodimensionaldistributedvortexmotion[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:06:08 - INFO - __main__ -   Generated: generalizedhelm##hol##tz-ki##rch##hoffmodelfortwodimensionaltwotwoflows[SEP]the------------\n",
            "Train iter:  28%|██▊       | 699/2531 [18:36<48:37,  1.59s/it]02/01/2020 13:08:47 - INFO - __main__ -   Epoch 3, step 699, loss 0.23275262117385864. lr 1.2e-05.\n",
            "02/01/2020 13:08:47 - INFO - __main__ -   Ground: [CLS]quan##ti##zationbasedfastinnerproductsearch[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:08:47 - INFO - __main__ -   Generated: quan##ti##zationbasedfastinnerproduct[SEP][SEP][SEP]-------------------\n",
            "Train iter:  32%|███▏      | 799/2531 [21:16<45:44,  1.58s/it]02/01/2020 13:11:27 - INFO - __main__ -   Epoch 3, step 799, loss 0.24974821507930756. lr 1.2e-05.\n",
            "02/01/2020 13:11:27 - INFO - __main__ -   Ground: [CLS]fastcorrelationgreeksbyad##jo##intalgorithm##icdifferentiation[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:11:27 - INFO - __main__ -   Generated: fastcorrelationgreeksbyad##jo##intalgorithm##icdifferentiation[SEP][SEP]-----------------\n",
            "Train iter:  36%|███▌      | 899/2531 [23:56<43:15,  1.59s/it]02/01/2020 13:14:07 - INFO - __main__ -   Epoch 3, step 899, loss 0.23936288058757782. lr 1.2e-05.\n",
            "02/01/2020 13:14:07 - INFO - __main__ -   Ground: [CLS]robustmetriclearningbysmoothoptimization[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:14:07 - INFO - __main__ -   Generated: robustmetriclearningbysmoothoptimization[SEP][SEP]---------------------\n",
            "Train iter:  39%|███▉      | 999/2531 [26:35<40:22,  1.58s/it]02/01/2020 13:16:47 - INFO - __main__ -   Epoch 3, step 999, loss 0.21054604649543762. lr 1.2e-05.\n",
            "02/01/2020 13:16:47 - INFO - __main__ -   Ground: [CLS]comparisonofgall##edtrees[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:16:47 - INFO - __main__ -   Generated: comparisonofgall##edtrees[SEP][SEP]----------------------\n",
            "Train iter:  43%|████▎     | 1099/2531 [29:15<38:13,  1.60s/it]02/01/2020 13:19:27 - INFO - __main__ -   Epoch 3, step 1099, loss 0.23103837668895721. lr 1.2e-05.\n",
            "02/01/2020 13:19:27 - INFO - __main__ -   Ground: [CLS]chargeflu##ct##uationeffectsontheshapeofflexiblepoly##amp##hol##yte##swithapplicationstointrinsic##allydisorder##edproteins[SEP][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:19:27 - INFO - __main__ -   Generated: chargeflu##ct##uationeffectsontheshapeofrandomlypoly##amp##hol##yte##swithapplicationstointrinsic##allypolymer##edpolymer[SEP][SEP]----\n",
            "Train iter:  47%|████▋     | 1199/2531 [31:55<35:06,  1.58s/it]02/01/2020 13:22:06 - INFO - __main__ -   Epoch 3, step 1199, loss 0.24090036749839783. lr 1.2e-05.\n",
            "02/01/2020 13:22:06 - INFO - __main__ -   Ground: [CLS]coe##xi##sten##ceinanin##hom##ogen##eousenvironment[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:22:06 - INFO - __main__ -   Generated: coe##xi##sten##ceinanin##hom##ogen##eousenvironment[SEP]by----------------\n",
            "Train iter:  51%|█████▏    | 1299/2531 [34:35<32:38,  1.59s/it]02/01/2020 13:24:46 - INFO - __main__ -   Epoch 3, step 1299, loss 0.22615206241607666. lr 1.2e-05.\n",
            "02/01/2020 13:24:46 - INFO - __main__ -   Ground: [CLS]anage-structuredcontinuummodelformy##x##ob##act##eria[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:24:46 - INFO - __main__ -   Generated: anage-structuredcontinuummodelformy##x##ob##act##eria[SEP][SEP]---------------\n",
            "Train iter:  55%|█████▌    | 1399/2531 [37:15<29:55,  1.59s/it]02/01/2020 13:27:26 - INFO - __main__ -   Epoch 3, step 1399, loss 0.22088056802749634. lr 1.2e-05.\n",
            "02/01/2020 13:27:26 - INFO - __main__ -   Ground: [CLS]capitalstructureinu.s.,aquan##tileregressionapproachwithmacro##economicimpacts[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:27:26 - INFO - __main__ -   Generated: capitalstructureinu.s.,aquan##tileregressionapproachwithmacro##economicimpacts[SEP][SEP]----------\n",
            "Train iter:  59%|█████▉    | 1499/2531 [39:55<27:25,  1.59s/it]02/01/2020 13:30:06 - INFO - __main__ -   Epoch 3, step 1499, loss 0.23006029427051544. lr 1.2e-05.\n",
            "02/01/2020 13:30:06 - INFO - __main__ -   Ground: [CLS]amasterequationapproachtooptionpricing[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:30:06 - INFO - __main__ -   Generated: amasterequationapproachtooptionpricing[SEP][SEP]--------------------\n",
            "Train iter:  63%|██████▎   | 1599/2531 [42:35<24:32,  1.58s/it]02/01/2020 13:32:46 - INFO - __main__ -   Epoch 3, step 1599, loss 0.23536086082458496. lr 1.2e-05.\n",
            "02/01/2020 13:32:46 - INFO - __main__ -   Ground: [CLS]towardimprovingthequalityofdoctoraleducation:afocusonstatistics,researchmethods,anddissertationsupervision[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:32:46 - INFO - __main__ -   Generated: towardimprovingthequalityofdoctoraleducation:afocusonstatistics,researchmethods,andresearchsupervision[SEP][SEP]--------\n",
            "Train iter:  67%|██████▋   | 1699/2531 [45:15<22:11,  1.60s/it]02/01/2020 13:35:26 - INFO - __main__ -   Epoch 3, step 1699, loss 0.2344144731760025. lr 1.2e-05.\n",
            "02/01/2020 13:35:26 - INFO - __main__ -   Ground: [CLS]localbehaviorofsparseanalysisregular##ization:applicationstoriskestimation[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:35:26 - INFO - __main__ -   Generated: localanalysisofsparseanalysisregular##ization:applicationstoriskestimation[SEP][SEP]---------------\n",
            "Train iter:  71%|███████   | 1799/2531 [47:54<19:19,  1.58s/it]02/01/2020 13:38:06 - INFO - __main__ -   Epoch 3, step 1799, loss 0.23092646896839142. lr 1.2e-05.\n",
            "02/01/2020 13:38:06 - INFO - __main__ -   Ground: [CLS]sequencematchingalgorithmsandpairingofnon##co##dingrna##s[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:38:06 - INFO - __main__ -   Generated: sequencematchingandandpairingofnon##co##dingrna##s[SEP]energy----------------\n",
            "Train iter:  75%|███████▌  | 1899/2531 [50:35<16:48,  1.60s/it]02/01/2020 13:40:46 - INFO - __main__ -   Epoch 3, step 1899, loss 0.22575221955776215. lr 1.2e-05.\n",
            "02/01/2020 13:40:46 - INFO - __main__ -   Ground: [CLS]dcapproximationapproachesforsparseoptimization[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:40:46 - INFO - __main__ -   Generated: dcapproximationapproachesforsparseoptimization[SEP]via---------------------\n",
            "Train iter:  79%|███████▉  | 1999/2531 [53:14<13:57,  1.57s/it]02/01/2020 13:43:25 - INFO - __main__ -   Epoch 3, step 1999, loss 0.25280866026878357. lr 1.2e-05.\n",
            "02/01/2020 13:43:25 - INFO - __main__ -   Ground: [CLS]hybridmethodologyforhourlyglobalradiationforecast##inginmediterraneanarea[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:43:25 - INFO - __main__ -   Generated: hybridmodelsforhourlyglobalradiationforecast##inginmediterraneanenergy[SEP]the----------------\n",
            "Train iter:  83%|████████▎ | 2099/2531 [55:54<11:28,  1.59s/it]02/01/2020 13:46:05 - INFO - __main__ -   Epoch 3, step 2099, loss 0.23634345829486847. lr 1.2e-05.\n",
            "02/01/2020 13:46:05 - INFO - __main__ -   Ground: [CLS]real-timehighlyaccuratedensedepthonapowerbudgetusinganf##pg##a-cpuhybridsoc[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:46:05 - INFO - __main__ -   Generated: real-timeaccurateaccuratedepthdepthonafbasedusinganf##pg##a-cpuintegrated[SEP][SEP][SEP]-------\n",
            "Train iter:  87%|████████▋ | 2199/2531 [58:34<08:45,  1.58s/it]02/01/2020 13:48:45 - INFO - __main__ -   Epoch 3, step 2199, loss 0.24247145652770996. lr 1.2e-05.\n",
            "02/01/2020 13:48:45 - INFO - __main__ -   Ground: [CLS]theoriginofinference:ed##iac##aranecologyandtheevolutionofbay##esianbrains[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:48:45 - INFO - __main__ -   Generated: theevolutionofinference:the##iac,,andtheevolutionofbay##esiansp[SEP][SEP]-----------\n",
            "Train iter:  91%|█████████ | 2299/2531 [1:01:13<06:09,  1.59s/it]02/01/2020 13:51:25 - INFO - __main__ -   Epoch 3, step 2299, loss 0.2511059641838074. lr 1.2e-05.\n",
            "02/01/2020 13:51:25 - INFO - __main__ -   Ground: [CLS]detectingcommunitystructuresinhi-cgen##omicdata[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:51:25 - INFO - __main__ -   Generated: detectingcommunitystructuresinhi-cgen##omicdata[SEP][SEP]-----------------\n",
            "Train iter:  95%|█████████▍| 2399/2531 [1:03:53<03:28,  1.58s/it]02/01/2020 13:54:04 - INFO - __main__ -   Epoch 3, step 2399, loss 0.25181475281715393. lr 1.2e-05.\n",
            "02/01/2020 13:54:04 - INFO - __main__ -   Ground: [CLS]comment:micro##ar##ray##s,empiricalbay##esandthetwo-groupsmodel[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:54:04 - INFO - __main__ -   Generated: comment:micro##ar##ray##s,empiricalbay##esandthetwo-groupsmodel[SEP][SEP]-----------\n",
            "Train iter:  99%|█████████▊| 2499/2531 [1:06:33<00:50,  1.59s/it]02/01/2020 13:56:44 - INFO - __main__ -   Epoch 3, step 2499, loss 0.2617168724536896. lr 1.2e-05.\n",
            "02/01/2020 13:56:44 - INFO - __main__ -   Ground: [CLS]analternativeproofofaresultoftak##ao##ka[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 13:56:44 - INFO - __main__ -   Generated: anproofproofofatakoftak##ae##ka[SEP]under-----------------\n",
            "Train iter: 100%|██████████| 2531/2531 [1:07:24<00:00,  1.59s/it]\n",
            "02/01/2020 13:57:36 - INFO - __main__ -   Model saved\n",
            "02/01/2020 13:57:41 - INFO - __main__ -   Source: [CLS]thisworktreatsonthequestionwhetheragivenmapf:m->bofsmoothclosedmanifold##sishomo##top##ictoasmoothfiberbundle.wedefineafirstobstructioninh^1(b;w##h(\\pi_1(e)))and,providedthatthisobstructionvanish##esandoneadditionalconditionisverified,asecondobstructioninw##h(\\pi_1(e))>.bothelementsvanishiftheanswertotheabovequestionispositive.inthecasewherebisthe1-sphereandthedimensionofmexceedsfive,weshowthattheconverseisalsotrue,using[SEP]\n",
            "02/01/2020 13:57:41 - INFO - __main__ -   Beam Generated: theobstructionoffiberbundlesoffiberbundles[SEP]\n",
            "02/01/2020 13:57:41 - INFO - __main__ -   ***** Running validation *****\n",
            "Val iter: 100%|██████████| 281/281 [19:13<00:00,  4.09s/it]\n",
            "02/01/2020 14:16:55 - INFO - __main__ -   ******Validation results******\n",
            "02/01/2020 14:16:55 - INFO - __main__ -   beam_size: 3 n_best: 3 Rouge-1: 0.7448097263738733 Rouge-2: 0.5951796621970094\n",
            "02/01/2020 14:16:55 - INFO - __main__ -   Validation finished.\n",
            "02/01/2020 14:16:55 - INFO - __main__ -   Epoch 3 change lr 8.000000000000001e-06.\n",
            "02/01/2020 14:16:55 - INFO - __main__ -   Epoch 3 finished.\n",
            "Train iter:   4%|▍         | 99/2531 [02:37<1:04:15,  1.59s/it]02/01/2020 14:19:34 - INFO - __main__ -   Epoch 4, step 99, loss 0.2623122036457062. lr 8.000000000000001e-06.\n",
            "02/01/2020 14:19:34 - INFO - __main__ -   Ground: [CLS]theho##lom##or##phyconjectureforidealsindimensiontwo[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 14:19:34 - INFO - __main__ -   Generated: theho##lom##or##phyconjectureforidealsintwo-[SEP][SEP]----------------\n",
            "Train iter:   8%|▊         | 199/2531 [05:17<1:01:32,  1.58s/it]02/01/2020 14:22:14 - INFO - __main__ -   Epoch 4, step 199, loss 0.24192126095294952. lr 8.000000000000001e-06.\n",
            "02/01/2020 14:22:14 - INFO - __main__ -   Ground: [CLS]lowenergypropertiesofthesu(m|n)super##sy##mme##trichal##dan##e-sha##st##ryspinchain[SEP][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 14:22:14 - INFO - __main__ -   Generated: lowenergypropertiesofthesu(m|n)super##sy##mme##trichal##dan##e-sha##st##ryspinchain[SEP][SEP]---\n",
            "Train iter:  12%|█▏        | 299/2531 [07:56<59:18,  1.59s/it]02/01/2020 14:24:53 - INFO - __main__ -   Epoch 4, step 299, loss 0.25618481636047363. lr 8.000000000000001e-06.\n",
            "02/01/2020 14:24:53 - INFO - __main__ -   Ground: [CLS]st##och##asticintegralrepresentationsofquantummartin##gal##esonmultiplef##ockspace[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 14:24:53 - INFO - __main__ -   Generated: quantum##och##asticintegralrepresentationsofquantummartin##gal##esonmultif##ockspace[SEP]to------------\n",
            "Train iter:  16%|█▌        | 399/2531 [10:36<56:12,  1.58s/it]02/01/2020 14:27:33 - INFO - __main__ -   Epoch 4, step 399, loss 0.2391272485256195. lr 8.000000000000001e-06.\n",
            "02/01/2020 14:27:33 - INFO - __main__ -   Ground: [CLS]res##ona##ntnormalformforevenperiodicf##puchains[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 14:27:33 - INFO - __main__ -   Generated: res##ona##ntnormalformforevenperiodicf##puchains[SEP][SEP]----------------\n",
            "Train iter:  20%|█▉        | 499/2531 [13:16<53:55,  1.59s/it]02/01/2020 14:30:12 - INFO - __main__ -   Epoch 4, step 499, loss 0.24039329588413239. lr 8.000000000000001e-06.\n",
            "02/01/2020 14:30:12 - INFO - __main__ -   Ground: [CLS]apatternmixturemodelforapaired$2\\times##2$crossoverdesign[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 14:30:12 - INFO - __main__ -   Generated: apatternmixturemodelforapaired$2\\times##2$crossoverdesign[SEP]with------------\n",
            "Train iter:  24%|██▎       | 599/2531 [15:56<50:57,  1.58s/it]02/01/2020 14:32:52 - INFO - __main__ -   Epoch 4, step 599, loss 0.22865979373455048. lr 8.000000000000001e-06.\n",
            "02/01/2020 14:32:52 - INFO - __main__ -   Ground: [CLS]generalizedhelm##hol##tz-ki##rch##hoffmodelfortwodimensionaldistributedvortexmotion[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 14:32:53 - INFO - __main__ -   Generated: generalizedhelm##hol##tz-ki##rch##hoffmodelfortwodimensionalvovoflows[SEP]the------------\n",
            "Train iter:  28%|██▊       | 699/2531 [18:35<48:27,  1.59s/it]02/01/2020 14:35:32 - INFO - __main__ -   Epoch 4, step 699, loss 0.2288099080324173. lr 8.000000000000001e-06.\n",
            "02/01/2020 14:35:32 - INFO - __main__ -   Ground: [CLS]quan##ti##zationbasedfastinnerproductsearch[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 14:35:32 - INFO - __main__ -   Generated: quan##ti##zationbasedfastinnerproductsearch[SEP][SEP]-------------------\n",
            "Train iter:  32%|███▏      | 799/2531 [21:15<45:33,  1.58s/it]02/01/2020 14:38:12 - INFO - __main__ -   Epoch 4, step 799, loss 0.24535736441612244. lr 8.000000000000001e-06.\n",
            "02/01/2020 14:38:12 - INFO - __main__ -   Ground: [CLS]fastcorrelationgreeksbyad##jo##intalgorithm##icdifferentiation[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 14:38:12 - INFO - __main__ -   Generated: fastcorrelationgreeksbyad##jo##intalgorithm##icdifferentiation[SEP][SEP]-----------------\n",
            "Train iter:  36%|███▌      | 899/2531 [23:55<43:26,  1.60s/it]02/01/2020 14:40:51 - INFO - __main__ -   Epoch 4, step 899, loss 0.23594607412815094. lr 8.000000000000001e-06.\n",
            "02/01/2020 14:40:51 - INFO - __main__ -   Ground: [CLS]robustmetriclearningbysmoothoptimization[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n",
            "02/01/2020 14:40:51 - INFO - __main__ -   Generated: robustmetriclearningbysmoothoptimization[SEP][SEP]---------------------\n",
            "Train iter:  36%|███▌      | 912/2531 [24:15<44:03,  1.63s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CADWqILgRlb",
        "colab_type": "code",
        "outputId": "519cada8-bac4-4414-d27d-33184887b722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M85q_0yll7_",
        "colab_type": "text"
      },
      "source": [
        "#Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3rb1QF9mMrB",
        "colab_type": "text"
      },
      "source": [
        "###Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvn5wKk-mFlO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ARGS(object):\n",
        "    # data_dir = 'data/processed_data'\n",
        "    bert_model = 'bert-base-uncased'\n",
        "    output_dir = 'output'\n",
        "    model_path =  'output/model_01-13-05:43:53/BertAbsSum_1.bin'\n",
        "    config_path = 'output/model_01-13-05:43:53/config.json'\n",
        "    result_path = 'result'\n",
        "    batch_size = 16\n",
        "    max_src_len = 512\n",
        "\n",
        "args = ARGS()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "with open(args.config_path, 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "model = BertAbsSum(args.bert_model, config['decoder_config'], device)\n",
        "model.load_state_dict(torch.load(args.model_path))\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W46pBZXuX6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gio6mNTmmQR-",
        "colab_type": "text"
      },
      "source": [
        "###Generate titles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9Bti4I4ljz5",
        "colab_type": "code",
        "outputId": "58b0257f-cf52-42fd-c173-1b391ec0f2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "set_seed(1616161)\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "# test = pd.read_csv('../data/test.csv', encoding='utf8')\n",
        "\n",
        "titles = []\n",
        "\n",
        "for row in tqdm(test.iterrows(), desc=\"Iteration\", total = test.shape[0], position=0):\n",
        "  i, text = row\n",
        "  src, src_mask = convert_one_example(text[0], args.max_src_len, tokenizer)\n",
        "  pred, _ = model.beam_decode(src.to(device), src_mask.to(device), 5, 5)  \n",
        "  # print(\" \".join(tokenizer.convert_ids_to_tokens(pred[0][0])).split('[SEP]')[0])\n",
        "\n",
        "  # De-tokenize.\n",
        "  tok_text = \" \".join(tokenizer.convert_ids_to_tokens(pred[0][0])).split('[SEP]')[0]\n",
        "  tok_text = tok_text.replace(\" ##\", \"\")\n",
        "  tok_text = tok_text.replace(\"##\", \"\")  \n",
        "  \n",
        "  # tok_text = ''\n",
        "  # for t in tokenizer.convert_ids_to_tokens(pred[0][0]):\n",
        "  #   tok_text += ' ' + t if not t.startswith('##') else t[2:]\n",
        "  # tok_text = tok_text.split('[SEP]')[0][1:]\n",
        "  titles.append(tok_text)\n",
        "\n",
        "submission_df = pd.DataFrame({'abstract': test.abstract, 'title': titles})\n",
        "submission_df.to_csv('predicted_titles.csv', index=False)  "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1000/1000 [04:10<00:00,  3.75it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVgoREBHmV5L",
        "colab_type": "text"
      },
      "source": [
        "###Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhR5PhD9l1Hr",
        "colab_type": "code",
        "outputId": "ef4826e0-ddba-4a31-ba02-0ef2d1cebe24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import string\n",
        "from nltk.util import ngrams\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "\n",
        "def generate_csv(input_file='predicted_titles.csv',\n",
        "                 output_file='submission.csv',\n",
        "                 voc_file='../data/vocs.pkl'):\n",
        "    '''\n",
        "    Generates file in format required for submitting result to Kaggle\n",
        "    \n",
        "    Parameters:\n",
        "        input_file (str) : path to csv file with your predicted titles.\n",
        "                           Should have two fields: abstract and title\n",
        "        output_file (str) : path to output submission file\n",
        "        voc_file (str) : path to voc.pkl file\n",
        "    '''\n",
        "    data = pd.read_csv(input_file)\n",
        "    with open(voc_file, 'rb') as voc_file:\n",
        "        vocs = pickle.load(voc_file)\n",
        "\n",
        "    with open(output_file, 'w') as res_file:\n",
        "        res_file.write('Id,Predict\\n')\n",
        "        \n",
        "    output_idx = 0\n",
        "    for row_idx, row in data.iterrows():\n",
        "        trg = row['title']\n",
        "        trg = trg.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
        "        trg.extend(['_'.join(ngram) for ngram in list(ngrams(trg, 2)) + list(ngrams(trg, 3))])\n",
        "        \n",
        "        VOCAB_stoi = vocs[row_idx]\n",
        "        trg_intersection = set(VOCAB_stoi.keys()).intersection(set(trg))\n",
        "        trg_vec = np.zeros(len(VOCAB_stoi))    \n",
        "\n",
        "        for word in trg_intersection:\n",
        "            trg_vec[VOCAB_stoi[word]] = 1\n",
        "\n",
        "        with open(output_file, 'a') as res_file:\n",
        "            for is_word in trg_vec:\n",
        "                res_file.write('{0},{1}\\n'.format(output_idx, int(is_word)))\n",
        "                output_idx += 1\n",
        "\n",
        "\n",
        "generate_csv()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHHG7mRcl1OO",
        "colab_type": "code",
        "outputId": "592ac72a-65a5-47db-a2c9-b872a80f109c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "!kaggle competitions submit -c title-generation -m \"model_01-30-05:17:03/BertAbsSum_1.bin 0.7321 Rouge-2: 0.5893\" -f submission.csv \n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "100% 2.84M/2.84M [00:02<00:00, 1.04MB/s]\n",
            "Successfully submitted to Arxiv Title Generation"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIF7JirNl1Ld",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}